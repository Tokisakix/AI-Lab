{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 实验题目\n",
    "\n",
    "使用决策树完成信誉度分类任务\n",
    "\n",
    "*注：由于机器学习相关实验需要大量用到jupyter notebook环境，为了带来更清晰的报告结构、更好的视觉体验，接下来的实验报告，我大部分会使用LaTeX编写。*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7364387f85d0bfe2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 实验原理\n",
    "\n",
    "## 决策树算法\n",
    "\n",
    "决策树是最经典的机器学习算法之一，主要用于分类和回归任务。其构建过程基于递归分割：\n",
    "\n",
    "- 从根节点开始，选择一个最优特征进行数据分割，生成子节点；\n",
    "\n",
    "- 在每个子节点上重复此过程，直到满足停止条件，如节点纯度达到一定程度、达到预设的最大深度等。\n",
    "\n",
    "## 特征划分方法\n",
    "\n",
    "上面说过，决策树就是不断分割特征的过程。这里介绍两种常见的分割算法。\n",
    "\n",
    "### ID3算法\n",
    "\n",
    "ID3 (Iterative Dichotomiser 3) 算法使用信息增益作为划分特征的标准。\n",
    "\n",
    "给定训练集 D 和特征 A，信息增益 $\\text{Gain}(D, A)$ 定义为：\n",
    "\n",
    "$$\n",
    "\\text{Gain}(D, A) = \\text{Entropy}(D) - \\sum_{v \\in \\text{Values}(A)} \\frac{|D_v|}{|D|} \\text{Entropy}(D_v)\n",
    "$$\n",
    "\n",
    "其中，$\\text{Entropy}(D)$ 是数据集 D 的熵，计算公式为：\n",
    "\n",
    "$$\n",
    "\\text{Entropy}(D) = -\\sum_{k} p_k \\log_2 p_k\n",
    "$$\n",
    "\n",
    "$p_k$ 是类别 k 在数据集 D 中的比例。\n",
    "\n",
    "### C4.5算法\n",
    "\n",
    "C4.5 算法改进了 ID3，通过使用信息增益率来克服 ID3 偏好选择具有更多值的特征的问题。\n",
    "\n",
    "信息增益率定义为信息增益和特征 A 的固有信息（分割信息）之比：\n",
    "\n",
    "$$\n",
    "\\text{Gain\\_ratio}(D, A) = \\frac{\\text{Gain}(D, A)}{\\text{Split\\_Info}(D, A)}\n",
    "$$\n",
    "\n",
    "其中，分割信息 $\\text{Split\\_Info}(D, A)$ 的计算公式为：\n",
    "\n",
    "$$\n",
    "\\text{Split\\_Info}(D, A) = -\\sum_{v \\in \\text{Values}(A)} \\frac{|D_v|}{|D|} \\log_2 \\frac{|D_v|}{|D|}\n",
    "$$\n",
    "\n",
    "## 剪枝方法\n",
    "\n",
    "剪枝是决策树算法中用于减少过拟合和提高模型泛化能力的重要技术。\n",
    "\n",
    "### 预剪枝\n",
    "\n",
    "预剪枝在决策树完全生成前进行。预剪枝提前停止某些分支的生长，防止过拟合。这可以通过设定最大深度、最小样本数或最小信息增益等参数来实现。\n",
    "\n",
    "### 后剪枝\n",
    "\n",
    "后剪枝在决策树完全生成后进行。后剪枝从树的底部开始，尝试去除某些子节点（用叶节点替换），并检验这种简化是否能提高测试集上的准确率，从而优化决策树的结构。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70a1f339cdb61d0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 实验过程\n",
    "\n",
    "我们开始进入编码环节。首先导入必须的包。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb225a55d701c916"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.649157100Z",
     "start_time": "2024-05-06T12:10:22.582453900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92dbd7e81180de2",
   "metadata": {},
   "source": [
    "## 准备数据\n",
    "\n",
    "首先我们读取题目给定的数据，并进行简单探索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144cd2bc4f307078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.712135500Z",
     "start_time": "2024-05-06T12:10:23.650159600Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/DT_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff12a476bf11f766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.735602700Z",
     "start_time": "2024-05-06T12:10:23.713536600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Undergrad MaritalStatus  TaxableIncome  WorkExperience Urban\n0        NO        Single          68833              10   YES\n1       YES      Divorced          33700              18   YES\n2        NO       Married          36925              30   YES\n3       YES        Single          50190              15   YES\n4        NO       Married          81002              28    NO",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Undergrad</th>\n      <th>MaritalStatus</th>\n      <th>TaxableIncome</th>\n      <th>WorkExperience</th>\n      <th>Urban</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NO</td>\n      <td>Single</td>\n      <td>68833</td>\n      <td>10</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>YES</td>\n      <td>Divorced</td>\n      <td>33700</td>\n      <td>18</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NO</td>\n      <td>Married</td>\n      <td>36925</td>\n      <td>30</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>YES</td>\n      <td>Single</td>\n      <td>50190</td>\n      <td>15</td>\n      <td>YES</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NO</td>\n      <td>Married</td>\n      <td>81002</td>\n      <td>28</td>\n      <td>NO</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00097c55c82048a",
   "metadata": {},
   "source": [
    "接下来，我们开始对数据进行预处理。\n",
    "\n",
    "根据题目要求，我们首先根据原数据中的`TaxableIncome`列，预处理出`Label`列。\n",
    "\n",
    "我们定义，当`TaxableIncome>30000`时，信用为好，即`Label=1`，反之`Label=0`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb44a6afeff85a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.736749300Z",
     "start_time": "2024-05-06T12:10:23.730019800Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Label'] = (df['TaxableIncome'] > 30000).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1299d8901c5763c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.748199700Z",
     "start_time": "2024-05-06T12:10:23.734600900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('TaxableIncome', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff460309a0328d70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.804415400Z",
     "start_time": "2024-05-06T12:10:23.745297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Undergrad MaritalStatus  WorkExperience Urban  Label\n0        NO        Single              10   YES      1\n1       YES      Divorced              18   YES      1\n2        NO       Married              30   YES      1\n3       YES        Single              15   YES      1\n4        NO       Married              28    NO      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Undergrad</th>\n      <th>MaritalStatus</th>\n      <th>WorkExperience</th>\n      <th>Urban</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NO</td>\n      <td>Single</td>\n      <td>10</td>\n      <td>YES</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>YES</td>\n      <td>Divorced</td>\n      <td>18</td>\n      <td>YES</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NO</td>\n      <td>Married</td>\n      <td>30</td>\n      <td>YES</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>YES</td>\n      <td>Single</td>\n      <td>15</td>\n      <td>YES</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NO</td>\n      <td>Married</td>\n      <td>28</td>\n      <td>NO</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e1427cbf4156d",
   "metadata": {},
   "source": [
    "除了预处理出`Label`列外，考虑到决策树的特征输入类型应该为`int`而非`string`，我们还需要将原数据中的`Undergrad`列等进行预处理。\n",
    "\n",
    "以`Undergrad`列为例。我们需要将`NO`映射到`0`，`YES`映射为`1`。\n",
    "\n",
    "事实上，`sklearn`库的决策树是可以接受`string`作为输入类型的。但是考虑到我们这里是自己手写决策树，最好还是处理为`int`更为方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69e724a3fe85a0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.871090700Z",
     "start_time": "2024-05-06T12:10:23.751023600Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Undergrad']     = df['Undergrad'].map({'NO': 0, 'YES': 1})\n",
    "df['MaritalStatus'] = df['MaritalStatus'].map({'Single': 0, 'Divorced': 1, 'Married': 2})\n",
    "df['Urban']         = df['Urban'].map({'NO': 0, 'YES': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2206b404d808fd0",
   "metadata": {},
   "source": [
    "我们接下来处理`WorkExperience`列。这一列原本的数据是连续的整数，但在决策树中，输入特征应该为类别而非具体的数值。\n",
    "\n",
    "因此，我们对`WorkExperience`列以 $5$ 为区间进行划分，将原本连续的的 $0\\sim 40$ 工作经验，划分为离散的 $0\\sim 8$ 类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a788e0f578e9ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.871090700Z",
     "start_time": "2024-05-06T12:10:23.759102800Z"
    }
   },
   "outputs": [],
   "source": [
    "bins   = [0, 5, 10, 15, 20, 25, 30, 35, 40]\n",
    "labels = [0, 1, 2 , 3 , 4 , 5 , 6 , 7 , 8 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa73283c4a0120e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.871090700Z",
     "start_time": "2024-05-06T12:10:23.763616200Z"
    }
   },
   "outputs": [],
   "source": [
    "df['WorkExperience'] = np.digitize(df['WorkExperience'], bins=bins, right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64645af9aac2be96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.871090700Z",
     "start_time": "2024-05-06T12:10:23.770912500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Undergrad  MaritalStatus  WorkExperience  Urban  Label\n0          0              0               2      1      1\n1          1              1               4      1      1\n2          0              2               6      1      1\n3          1              0               3      1      1\n4          0              2               6      0      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Undergrad</th>\n      <th>MaritalStatus</th>\n      <th>WorkExperience</th>\n      <th>Urban</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800d0d7c96f91a7",
   "metadata": {},
   "source": [
    "直到现在，我们已经完成了数据的预处理。我们顺手保存一下。预处理后的数据随压缩包一起发送。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e5b3b4d091474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.872153400Z",
     "start_time": "2024-05-06T12:10:23.780122800Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/DT_data_processed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39508f3ae66fc8b",
   "metadata": {},
   "source": [
    "对于预处理后的数据，我们将其从`dataframe`转换为`numpy`，然后按照一定比例，划分训练集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa4d8ab5c340ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.872153400Z",
     "start_time": "2024-05-06T12:10:23.785700300Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df.values.astype(np.int32)\n",
    "# np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f46e0a9f6f9a7c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.872153400Z",
     "start_time": "2024-05-06T12:10:23.792037300Z"
    }
   },
   "outputs": [],
   "source": [
    "split            = round(len(data) * 0.65)\n",
    "train, test      = data[:split], data[split:]\n",
    "X_train, Y_train = train[:, :-1], train[:, -1]\n",
    "X_test, Y_test   = test[:, :-1], test[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5b418f6459cba",
   "metadata": {},
   "source": [
    "## 模型搭建\n",
    "\n",
    "接下来，我们开始搭建决策树模型。本次实验中，我们采取ID3方法划分特征。\n",
    "\n",
    "首先编写计算数据集中熵的函数。对于数据集 D ，计算熵的公式如下:\n",
    "\n",
    "$$\n",
    "\\text{Entropy}(D) = -\\sum_{k} p_k \\log_2 p_k\n",
    "$$\n",
    "\n",
    "$p_k$ 是类别 k 在数据集 D 中的比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81638b6e3ac4b660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.872153400Z",
     "start_time": "2024-05-06T12:10:23.797417900Z"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    probabilities  = counts / counts.sum()\n",
    "    return -np.sum(probabilities * np.log2(probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来编写寻找最佳划分属性的函数。根据ID3算法的思想，我们基于信息增益划分。\n",
    "\n",
    "给定训练集 D 和特征 A，信息增益 $\\text{Gain}(D, A)$ 定义为：\n",
    "\n",
    "$$\n",
    "\\text{Gain}(D, A) = \\text{Entropy}(D) - \\sum_{v \\in \\text{Values}(A)} \\frac{|D_v|}{|D|} \\text{Entropy}(D_v)\n",
    "$$\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5630451575417f5"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac738099f958a45c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.873255500Z",
     "start_time": "2024-05-06T12:10:23.802883Z"
    }
   },
   "outputs": [],
   "source": [
    "def ID3(X, Y):\n",
    "    base_entropy   = entropy(Y)\n",
    "    best_info_gain = 0\n",
    "    best_feature   = -1\n",
    "    n_features     = X.shape[1]\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        unique_values   = np.unique(X[:, i])\n",
    "        feature_entropy = 0\n",
    "        \n",
    "        for value in unique_values:\n",
    "            sub_Y = Y[X[:, i] == value]\n",
    "            prob  = len(sub_Y) / len(Y)\n",
    "            feature_entropy += prob * entropy(sub_Y)\n",
    "        \n",
    "        info_gain = base_entropy - feature_entropy\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_feature   = i\n",
    "    \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来编写构建决策树的函数。就像在数据结构课程中学过的一样，我们采取递归的方法构建树即可。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33706fd303437392"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c976c6d6f424da27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.935507300Z",
     "start_time": "2024-05-06T12:10:23.811310100Z"
    }
   },
   "outputs": [],
   "source": [
    "def build(X, Y, depth=0, max_depth=5):\n",
    "    if len(np.unique(Y)) == 1 or depth == max_depth:\n",
    "        return np.unique(Y, return_counts=True)[0][np.argmax(np.unique(Y, return_counts=True)[1])]\n",
    "    \n",
    "    best_feature  = ID3(X, Y)\n",
    "    tree          = {best_feature: {}}\n",
    "    unique_values = np.unique(X[:, best_feature])\n",
    "    \n",
    "    for value in unique_values:\n",
    "        sub_X     = X[X[:, best_feature] == value]\n",
    "        sub_Y     = Y[X[:, best_feature] == value]\n",
    "        subtree   = build(sub_X, sub_Y, depth+1, max_depth)\n",
    "        tree[best_feature][value] = subtree\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "最后编写进行预测和计算准确率的函数。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d03a5aa75d00544c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "155a07aa8f04537b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:23.935507300Z",
     "start_time": "2024-05-06T12:10:23.816443200Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    \n",
    "    feature       = next(iter(tree))\n",
    "    feature_value = sample[feature]\n",
    "    \n",
    "    if feature_value in tree[feature]:\n",
    "        return predict(tree[feature][feature_value], sample)\n",
    "    else:\n",
    "        return np.random.choice(np.unique(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ababba4f34e1ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:24.013066800Z",
     "start_time": "2024-05-06T12:10:23.820894800Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 实验结果\n",
    "\n",
    "下面我们使用编写好的决策树模型进行预测。\n",
    "\n",
    "首先我们用训练集构建决策树，看看树长什么样子。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "146cef6fb0614a3a"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59ad6b023a503e61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:24.038614300Z",
     "start_time": "2024-05-06T12:10:23.823765400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{2: {0: {0: {0: {1: {1: 1, 2: {-1: {1: {-1: {1: 0}}}}}}, 1: 1}},\n  1: {1: {0: {0: {0: {3: {0: {-1: {0: 1}}, 1: 1}},\n      1: {3: {0: 1, 1: {-1: {1: 1}}}}}},\n    1: {3: {0: {0: {0: 0, 1: {-1: {0: 1}}}},\n      1: {0: {0: {-1: {1: 1}}, 1: {-1: {1: 1}}}}}},\n    2: {3: {0: {0: {0: 1, 1: {-1: {0: 1}}}},\n      1: {0: {0: {-1: {1: 1}}, 1: {-1: {1: 0}}}}}}}},\n  2: {3: {0: {1: {0: {0: {0: {-1: {0: 0}}, 1: {-1: {0: 1}}}},\n      1: {0: {0: {-1: {0: 1}}, 1: {-1: {0: 1}}}},\n      2: {-1: {0: {-1: {0: 0}}}}}},\n    1: {1: {0: {0: {0: {-1: {1: 1}}, 1: {-1: {1: 1}}}},\n      1: {0: {0: {-1: {1: 1}}, 1: {-1: {1: 0}}}},\n      2: {0: {0: {-1: {1: 1}}, 1: {-1: {1: 1}}}}}}}},\n  3: {1: {0: {3: {0: {0: {0: {-1: {0: 1}}, 1: {-1: {0: 1}}}},\n      1: {0: {0: 1, 1: {-1: {1: 1}}}}}},\n    1: {3: {0: {0: {0: {-1: {0: 1}}, 1: 1}},\n      1: {0: {0: {-1: {1: 1}}, 1: {-1: {1: 0}}}}}},\n    2: {0: {0: {3: {0: {-1: {0: 0}}, 1: {-1: {1: 1}}}},\n      1: {3: {0: {-1: {0: 1}}, 1: {-1: {1: 1}}}}}}}},\n  4: {3: {0: {0: {0: {1: {0: {-1: {0: 0}}, 1: {-1: {0: 1}}, 2: 1}},\n      1: {1: {0: 1, 1: {-1: {0: 1}}, 2: {-1: {0: 0}}}}}},\n    1: {1: {0: {0: {0: {-1: {1: 0}}, 1: {-1: {1: 1}}}},\n      1: {-1: {1: {-1: {1: 0}}}},\n      2: {-1: {1: {-1: {1: 1}}}}}}}},\n  5: {0: {0: {3: {0: 1, 1: {1: {0: 1, 1: {-1: {1: 1}}, 2: {-1: {1: 1}}}}}},\n    1: {1: {0: {3: {0: {-1: {0: 1}}, 1: 1}},\n      1: {3: {0: {-1: {0: 1}}, 1: 1}},\n      2: {3: {0: {-1: {0: 1}}, 1: {-1: {1: 1}}}}}}}},\n  6: {1: {0: {0: {0: {3: {0: 1, 1: {-1: {1: 1}}}},\n      1: {3: {0: {-1: {0: 1}}, 1: 1}}}},\n    1: {0: {0: {3: {0: {-1: {0: 1}}, 1: 1}},\n      1: {3: {0: {-1: {0: 1}}, 1: {-1: {1: 1}}}}}},\n    2: {3: {0: {0: {0: {-1: {0: 1}}, 1: {-1: {0: 1}}}},\n      1: {0: {0: 1, 1: {-1: {1: 1}}}}}}}}}}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = build(X_train,Y_train)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "可能输出的决策树第一眼看过去不是那么易懂，这里以第一行为例简单解释一下。\n",
    "\n",
    "```\n",
    "{2: {0: {0: {0: {1: {1: 1, 2: {-1: {1: {-1: {1: 0}}}}}}, 1: 1}}...\n",
    "```\n",
    "\n",
    "- 最外层的 `{2: {...}}` 表示决策树的最顶层是基于特征索引 `2`（也就是WorkExperience） 来进行分割的。\n",
    "\n",
    "- 内层的 `{0: {...}, 1: 1}` 表示如果特征 `2` 的值为 `0`，则无法做出决策，需要进一步检查子树 `{...}`；如果特征 `2` 的值为 `1`，则直接预测类别为 `1`，也即信誉度为好。\n",
    "\n",
    "- 更深的层次也类似，不再赘述。\n",
    "\n",
    "下面查看决策树在训练集上的准确率。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f1c59d0ee5586c8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7769230769230769"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = np.array([predict(tree,sample)for sample in X_train])\n",
    "acc    = accuracy(Y_train,Y_pred)\n",
    "acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:24.038614300Z",
     "start_time": "2024-05-06T12:10:23.863678Z"
    }
   },
   "id": "17e0cd90f8183e37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面查看决策树在测试集上的准确率。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "409831907d6e8b76"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bd16712bf4b7a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:24.043626900Z",
     "start_time": "2024-05-06T12:10:23.874513600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.7333333333333333"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = np.array([predict(tree,sample)for sample in X_test])\n",
    "acc    = accuracy(Y_test,Y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 创新点\n",
    "\n",
    "## 后剪枝操作\n",
    "\n",
    "观察上面的结果可以发现，测试集上的准确率明显比训练集上的准确率低，说明决策树容易出现过拟合，导致泛化能力较差。\n",
    "\n",
    "为了解决这一点，我们需要进行后剪枝操作。具体来讲，我们从树的底部开始，逐步尝试用叶节点替换子节点，并检验这种简化是否能提高测试集上的准确率，从而优化决策树的结构。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d73a401155e11af"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65a4931aed0cd633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:24.043626900Z",
     "start_time": "2024-05-06T12:10:23.882537600Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut(tree, X_val, Y_val):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "\n",
    "    # 计算剪枝前准确率\n",
    "    y_pred           = np.array([predict(tree, sample) for sample in X_val])\n",
    "    initial_accuracy = np.sum(y_pred == Y_val) / len(Y_val)\n",
    "\n",
    "    # 将当前节点转换为叶节点\n",
    "    most_common      = np.bincount(Y_val).argmax()\n",
    "    new_accuracy     = np.sum(Y_val == most_common) / len(Y_val)\n",
    "\n",
    "    # 检查是否提升准确率\n",
    "    if new_accuracy >= initial_accuracy:\n",
    "        return most_common  \n",
    "    else:\n",
    "        for feature, branches in tree.items():\n",
    "            for value, subtree in branches.items():\n",
    "                subset_indices = X_val[:, int(feature)] == value\n",
    "                if np.any(subset_indices):\n",
    "                    X_sub_val  = X_val[subset_indices]\n",
    "                    y_sub_val  = Y_val[subset_indices]\n",
    "                    # 递归剪枝子树\n",
    "                    tree[feature][value] = cut(subtree, X_sub_val, y_sub_val)\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "对上面构建好的决策树，我们尝试后剪枝，并查看其后剪枝后在测试集上的表现结果。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9577910885d45fb5"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "tree   = cut(tree, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:24.043626900Z",
     "start_time": "2024-05-06T12:10:23.886054400Z"
    }
   },
   "id": "b763a3e5af2056b5"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8428571428571429"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = np.array([predict(tree,sample)for sample in X_test])\n",
    "acc    = accuracy(Y_test,Y_pred)\n",
    "acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:10:24.043626900Z",
     "start_time": "2024-05-06T12:10:23.891059200Z"
    }
   },
   "id": "955da653d11a33e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，测试集上的准确率明显提升，说明我们后剪枝的策略是有效的，增强了模型的泛化能力。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "594d2cd067b71a6c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 参考资料\n",
    "\n",
    "[周志华《机器学习》——决策树基本原理](https://www.bookstack.cn/read/Vay-keen-Machine-learning-learning-notes/spilt.1.4.md)\n",
    "\n",
    "[周志华《机器学习》——决策树剪枝处理](https://www.bookstack.cn/read/Vay-keen-Machine-learning-learning-notes/spilt.3.4.md)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "123f83f08cbac61f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
